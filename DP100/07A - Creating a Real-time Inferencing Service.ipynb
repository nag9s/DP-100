{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Real-Time Inferencing Service\n",
    "\n",
    "You've spent a lot of time in this course training and registering machine learning models. Now it's time to deploy a model as a real-time service that clients can use to get predictions from new data.\n",
    "\n",
    "## Connect to Your Workspace\n",
    "\n",
    "The first thing you need to do is to connect to your workspace using the Azure ML SDK.\n",
    "\n",
    "> **Note**: If the authenticated session with your Azure subscription has expired since you completed the previous exercise, you'll be prompted to reauthenticate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.58.0 to work with wsp-mlopsdemo\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Register a Model\n",
    "\n",
    "If you have completed the previous labs in this course, you will have registered many versions of the **diabetes_model** model, and you're ready to go.\n",
    "\n",
    "If you haven't, you can run the cell below to train and register the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment: diabetes-training\n",
      "Loading Data...\n",
      "Training a decision tree model\n",
      "Accuracy: 0.8913333333333333\n",
      "AUC: 0.8798149161649832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44079/3341331032.py:34: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  run.log('Accuracy', np.float(acc))\n",
      "/tmp/ipykernel_44079/3341331032.py:40: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  run.log('AUC', np.float(auc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and registered.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.core import Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Create an Azure ML experiment in your workspace\n",
    "experiment = Experiment(workspace = ws, name = \"diabetes-training-rt\")\n",
    "run = experiment.start_logging()\n",
    "print(\"Starting experiment:\", experiment.name)\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "diabetes = pd.read_csv('data/diabetes.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a decision tree model\n",
    "print('Training a decision tree model')\n",
    "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "# Save the trained model\n",
    "model_file = 'diabetes_model.pkl'\n",
    "joblib.dump(value=model, filename=model_file)\n",
    "run.upload_file(name = 'outputs/' + model_file, path_or_stream = './' + model_file)\n",
    "\n",
    "# Complete the run\n",
    "run.complete()\n",
    "\n",
    "# Register the model\n",
    "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
    "                   tags={'Training context':'Inline Training'},\n",
    "                   properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
    "\n",
    "print('Model trained and registered.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy a Model as a Web Service\n",
    "\n",
    "You have trained and registered a machine learning model that classifies patients based on the likelihood of them having diabetes. This model could be used in a production environment such as a doctor's surgery where only patients deemed to be at risk need to be subjected to a clinical test for diabetes. To support this scenario, you will deploy the model as a web service.\n",
    "\n",
    "First, let's determine what models you have registered in the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_model version: 4\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.8798149161649832\n",
      "\t Accuracy : 0.8913333333333333\n",
      "\n",
      "\n",
      "diabetes_model version: 3\n",
      "\t Training context : Estimator\n",
      "\t AUC : 0.8483208119806956\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n",
      "diabetes_model version: 2\n",
      "\t Training context : Estimator\n",
      "\t AUC : 0.8483208119806956\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n",
      "diabetes_model version: 1\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.88160336081812\n",
      "\t Accuracy : 0.8968888888888888\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right, now let's get the model that we want to deploy. By default, if we specify a model name, the latest version will be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_model version 4\n"
     ]
    }
   ],
   "source": [
    "model = ws.models['diabetes_model']\n",
    "print(model.name, 'version', model.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to create a web service to host this model, and this will require some code and configuration files; so let's create a folder for those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_service folder created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_name = 'diabetes_service'\n",
    "\n",
    "# Create a folder for the web service files\n",
    "experiment_folder = './' + folder_name\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "print(folder_name, 'folder created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The web service where we deploy the model will need some Python code to load the input data, get the model from the workspace, and generate and return predictions. We'll save this code in an *entry script* that will be deployed to the web service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting diabetes_service/score_diabetes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $folder_name/score_diabetes.py\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the deployed model file and load it\n",
    "    model_path = Model.get_model_path('diabetes_model')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    # Get the input data as a numpy array\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # Get a prediction from the model\n",
    "    predictions = model.predict(data)\n",
    "    # Get the corresponding classname for each prediction (0 or 1)\n",
    "    classnames = ['not-diabetic', 'diabetic']\n",
    "    predicted_classes = []\n",
    "    for prediction in predictions:\n",
    "        predicted_classes.append(classnames[prediction])\n",
    "    # Return the predictions as JSON\n",
    "    return json.dumps(predicted_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The web service will be hosted in a container, and the container will need to install any required Python dependencies when it gets initialized. In this case, our scoring code requires **scikit-learn**, so we'll create a .yml file that tells the container host to install this into the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dependency info in diabetes_service/diabetes_env.yml\n",
      "# Conda environment specification. The dependencies defined in this file will\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\n",
      "\n",
      "# Details about the Conda environment file format:\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "  # Currently Azure ML only supports 3.8 and later.\n",
      "- python=3.8.13\n",
      "\n",
      "- pip:\n",
      "    # Required packages for AzureML execution, history, and data preparation.\n",
      "  - azureml-defaults\n",
      "\n",
      "- scikit-learn\n",
      "channels:\n",
      "- anaconda\n",
      "- conda-forge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "# Add the dependencies for our model (AzureML defaults is already included)\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package(\"scikit-learn\")\n",
    "\n",
    "# Save the environment config as a .yml file\n",
    "env_file = folder_name + \"/diabetes_env.yml\"\n",
    "with open(env_file,\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "print(\"Saved dependency info in\", env_file)\n",
    "\n",
    "# Print the .yml file\n",
    "with open(env_file,\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you're ready to deploy. We'll deploy the container a service named **diabetes-service**. The deployment process includes the following steps:\n",
    "\n",
    "1. Define an inference configuration, which includes the scoring and environment files required to load and use the model.\n",
    "2. Define a deployment configuration that defines the execution environment in which the service will be hosted. In this case, an Azure Container Instance.\n",
    "3. Deploy the model as a web service.\n",
    "4. Verify the status of the deployed service.\n",
    "\n",
    "> **More Information**: For more details about model deployment, and options for target execution environments, see the [documentation](https://docs.microsoft.com/en-gb/azure/machine-learning/service/how-to-deploy-and-where).\n",
    "\n",
    "Deployment will take some time as it first runs a process to create a container image, and then runs a process to create a web service based on the image. When deployment has completed successfully, you'll see a status of **Healthy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44079/2370366935.py:14: FutureWarning: azureml.core.model:\n",
      "To leverage new model deployment capabilities, AzureML recommends using CLI/SDK v2 to deploy models as online endpoint, \n",
      "please refer to respective documentations \n",
      "https://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoints /\n",
      "https://docs.microsoft.com/azure/machine-learning/how-to-attach-kubernetes-anywhere \n",
      "For more information on migration, see https://aka.ms/acimoemigration \n",
      "To disable CLI/SDK v1 deprecation warning set AZUREML_LOG_DEPRECATION_WARNING_ENABLED to 'False'\n",
      "  service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2024-10-19 07:55:34+00:00 Creating Container Registry if not exists.\n",
      "2024-10-19 07:55:36+00:00 Use the existing image.\n",
      "2024-10-19 07:55:36+00:00 Generating deployment configuration.\n",
      "2024-10-19 07:55:38+00:00 Submitting deployment to compute..\n",
      "2024-10-19 07:55:48+00:00 Checking the status of deployment diabetes-service.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "# Configure the scoring environment\n",
    "inference_config = InferenceConfig(runtime= \"python\",\n",
    "                                   source_directory = folder_name,\n",
    "                                   entry_script=\"score_diabetes.py\",\n",
    "                                   conda_file=\"diabetes_env.yml\")\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
    "\n",
    "service_name = \"diabetes-service\"\n",
    "\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n",
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, the deployment has been successful and you can see a status of **Healthy**. If not, you can use the following code to check the status and get the service logs to help you troubleshoot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy\n",
      "/bin/bash: /azureml-envs/azureml_c0ce3e6b048e85d1440ae5b5f8420e29/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_c0ce3e6b048e85d1440ae5b5f8420e29/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_c0ce3e6b048e85d1440ae5b5f8420e29/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "2024-10-19T07:56:50,176630018+00:00 - rsyslog/run \n",
      "2024-10-19T07:56:50,179425350+00:00 - gunicorn/run \n",
      "2024-10-19T07:56:50,180981853+00:00 | gunicorn/run | \n",
      "2024-10-19T07:56:50,185303530+00:00 | gunicorn/run | ###############################################\n",
      "bash: /azureml-envs/azureml_c0ce3e6b048e85d1440ae5b5f8420e29/lib/libtinfo.so.6: no version information available (required by bash)\n",
      "2024-10-19T07:56:50,187119546+00:00 | gunicorn/run | AzureML Container Runtime Information\n",
      "2024-10-19T07:56:50,188760837+00:00 | gunicorn/run | ###############################################\n",
      "2024-10-19T07:56:50,190042095+00:00 | gunicorn/run | \n",
      "2024-10-19T07:56:50,193872998+00:00 | gunicorn/run | \n",
      "2024-10-19T07:56:50,194629446+00:00 - nginx/run \n",
      "2024-10-19T07:56:50,199304583+00:00 | gunicorn/run | AzureML image information: openmpi4.1.0-ubuntu20.04, Materializaton Build:20240918.v1\n",
      "2024-10-19T07:56:50,203052651+00:00 | gunicorn/run | \n",
      "2024-10-19T07:56:50,203884171+00:00 | gunicorn/run | \n",
      "2024-10-19T07:56:50,204712286+00:00 | gunicorn/run | PATH environment variable: /azureml-envs/azureml_c0ce3e6b048e85d1440ae5b5f8420e29/bin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n",
      "2024-10-19T07:56:50,207510844+00:00 | gunicorn/run | PYTHONPATH environment variable: \n",
      "2024-10-19T07:56:50,211832684+00:00 | gunicorn/run | \n",
      "2024-10-19T07:56:52,218191343+00:00 | gunicorn/run | CONDAPATH environment variable: /opt/miniconda\n",
      "\n",
      "# conda environments:\n",
      "#\n",
      "                      *  /azureml-envs/azureml_c0ce3e6b048e85d1440ae5b5f8420e29\n",
      "base                     /opt/miniconda\n",
      "\n",
      "2024-10-19T07:56:53,102955759+00:00 | gunicorn/run | \n",
      "2024-10-19T07:56:53,103933961+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)\n",
      "\n",
      "adal==1.2.7\n",
      "annotated-types==0.7.0\n",
      "argcomplete==3.5.1\n",
      "attrs==24.2.0\n",
      "azure-common==1.1.28\n",
      "azure-core==1.31.0\n",
      "azure-graphrbac==0.61.1\n",
      "azure-identity==1.19.0\n",
      "azure-mgmt-authorization==4.0.0\n",
      "azure-mgmt-containerregistry==10.3.0\n",
      "azure-mgmt-core==1.4.0\n",
      "azure-mgmt-keyvault==10.3.1\n",
      "azure-mgmt-network==27.0.0\n",
      "azure-mgmt-resource==23.1.1\n",
      "azure-mgmt-storage==21.2.1\n",
      "azureml-core==1.58.0\n",
      "azureml-dataprep==5.1.6\n",
      "azureml-dataprep-native==41.0.0\n",
      "azureml-dataprep-rslex==2.22.4\n",
      "azureml-dataset-runtime==1.58.0\n",
      "azureml-defaults==1.58.0\n",
      "azureml-inference-server-http==1.3.3\n",
      "backports.tempfile==1.0\n",
      "backports.weakref==1.0.post1\n",
      "bcrypt==4.2.0\n",
      "blinker==1.8.2\n",
      "Brotli @ file:///croot/brotli-split_1714483155106/work\n",
      "cachetools==5.5.0\n",
      "certifi @ file:///croot/certifi_1725551672989/work/certifi\n",
      "cffi==1.17.1\n",
      "charset-normalizer @ file:///croot/charset-normalizer_1721748349566/work\n",
      "click==8.1.7\n",
      "cloudpickle==2.2.1\n",
      "contextlib2==21.6.0\n",
      "cryptography==43.0.3\n",
      "docker==7.1.0\n",
      "Flask==2.3.2\n",
      "Flask-Cors==5.0.0\n",
      "fusepy==3.0.1\n",
      "google-api-core==2.21.0\n",
      "google-auth==2.35.0\n",
      "googleapis-common-protos==1.65.0\n",
      "gunicorn==22.0.0\n",
      "humanfriendly==10.0\n",
      "idna @ file:///croot/idna_1714398848350/work\n",
      "importlib_metadata==8.5.0\n",
      "importlib_resources==6.4.5\n",
      "inference-schema==1.8\n",
      "isodate==0.7.2\n",
      "itsdangerous==2.2.0\n",
      "jeepney==0.8.0\n",
      "Jinja2==3.1.4\n",
      "jmespath==1.0.1\n",
      "joblib @ file:///croot/joblib_1718217211762/work\n",
      "jsonpickle==3.3.0\n",
      "jsonschema==4.23.0\n",
      "jsonschema-specifications==2023.12.1\n",
      "knack==0.12.0\n",
      "MarkupSafe==2.1.5\n",
      "msal==1.31.0\n",
      "msal-extensions==1.2.0\n",
      "msrest==0.7.1\n",
      "msrestazure==0.6.4.post1\n",
      "ndg-httpsclient==0.5.1\n",
      "numpy==1.23.5\n",
      "oauthlib==3.2.2\n",
      "opencensus==0.11.4\n",
      "opencensus-context==0.1.3\n",
      "opencensus-ext-azure==1.1.13\n",
      "packaging @ file:///croot/packaging_1720101850331/work\n",
      "paramiko==3.5.0\n",
      "pathspec==0.12.1\n",
      "pkginfo==1.11.2\n",
      "pkgutil_resolve_name==1.3.10\n",
      "platformdirs @ file:///croot/platformdirs_1692205439124/work\n",
      "pooch @ file:///croot/pooch_1695850093751/work\n",
      "portalocker==2.10.1\n",
      "proto-plus==1.24.0\n",
      "protobuf==5.28.2\n",
      "psutil==6.1.0\n",
      "pyarrow==17.0.0\n",
      "pyasn1==0.6.1\n",
      "pyasn1_modules==0.4.1\n",
      "pycparser==2.22\n",
      "pydantic==2.7.4\n",
      "pydantic-settings==2.6.0\n",
      "pydantic_core==2.18.4\n",
      "Pygments==2.18.0\n",
      "PyJWT==2.9.0\n",
      "PyNaCl==1.5.0\n",
      "pyOpenSSL==24.2.1\n",
      "PySocks @ file:///tmp/build/80754af9/pysocks_1605305779399/work\n",
      "python-dateutil==2.9.0.post0\n",
      "python-dotenv==1.0.1\n",
      "pytz==2024.2\n",
      "PyYAML==6.0.2\n",
      "referencing==0.35.1\n",
      "requests @ file:///croot/requests_1721410876868/work\n",
      "requests-oauthlib==2.0.0\n",
      "rpds-py==0.20.0\n",
      "rsa==4.9\n",
      "scikit-learn @ file:///croot/scikit-learn_1694788527225/work\n",
      "scipy==1.10.1\n",
      "SecretStorage==3.3.3\n",
      "six==1.16.0\n",
      "tabulate==0.9.0\n",
      "threadpoolctl @ file:///croot/threadpoolctl_1719407800858/work\n",
      "typing_extensions==4.12.2\n",
      "urllib3 @ file:///croot/urllib3_1727769808118/work\n",
      "Werkzeug==3.0.4\n",
      "wrapt==1.16.0\n",
      "zipp==3.20.2\n",
      "\n",
      "2024-10-19T07:56:53,722135006+00:00 | gunicorn/run | \n",
      "2024-10-19T07:56:53,723017773+00:00 | gunicorn/run | Entry script directory: /var/azureml-app/diabetes_service\n",
      "2024-10-19T07:56:53,723850626+00:00 | gunicorn/run | \n",
      "2024-10-19T07:56:53,724728284+00:00 | gunicorn/run | ###############################################\n",
      "2024-10-19T07:56:53,726035836+00:00 | gunicorn/run | Dynamic Python Package Installation\n",
      "2024-10-19T07:56:53,730653640+00:00 | gunicorn/run | ###############################################\n",
      "2024-10-19T07:56:53,731726181+00:00 | gunicorn/run | \n",
      "2024-10-19T07:56:53,733036195+00:00 | gunicorn/run | Dynamic Python package installation is disabled.\n",
      "2024-10-19T07:56:53,734015171+00:00 | gunicorn/run | \n",
      "2024-10-19T07:56:53,734992685+00:00 | gunicorn/run | ###############################################\n",
      "2024-10-19T07:56:53,736071297+00:00 | gunicorn/run | Checking if the Python package azureml-inference-server-http is installed\n",
      "2024-10-19T07:56:53,740313261+00:00 | gunicorn/run | ###############################################\n",
      "2024-10-19T07:56:53,741152306+00:00 | gunicorn/run | \n",
      "2024-10-19T07:56:54,325337208+00:00 | gunicorn/run | \n",
      "2024-10-19T07:56:54,326710079+00:00 | gunicorn/run | ###############################################\n",
      "2024-10-19T07:56:54,328425839+00:00 | gunicorn/run | AzureML Inference Server\n",
      "2024-10-19T07:56:54,329582016+00:00 | gunicorn/run | ###############################################\n",
      "2024-10-19T07:56:54,330644058+00:00 | gunicorn/run | \n",
      "2024-10-19T07:56:54,331965112+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\n",
      "2024-10-19 07:56:54,570 I [74] azmlinfsrv - Loaded logging config from /azureml-envs/azureml_c0ce3e6b048e85d1440ae5b5f8420e29/lib/python3.8/site-packages/azureml_inference_server_http/logging.json\n",
      "2024-10-19 07:56:54,605 I [74] gunicorn.error - Starting gunicorn 22.0.0\n",
      "2024-10-19 07:56:54,607 I [74] gunicorn.error - Listening at: http://0.0.0.0:31311 (74)\n",
      "2024-10-19 07:56:54,607 I [74] gunicorn.error - Using worker: sync\n",
      "2024-10-19 07:56:54,609 I [135] gunicorn.error - Booting worker with pid: 135\n",
      "\n",
      "Azure ML Inferencing HTTP server v1.3.3\n",
      "\n",
      "\n",
      "Server Settings\n",
      "---------------\n",
      "Entry Script Name: /var/azureml-app/diabetes_service/score_diabetes.py\n",
      "Model Directory: /var/azureml-app/azureml-models/diabetes_model/4\n",
      "Config File: None\n",
      "Worker Count: 1\n",
      "Worker Timeout (seconds): 300\n",
      "Server Port: 31311\n",
      "Health Port: 31311\n",
      "Application Insights Enabled: false\n",
      "Application Insights Key: None\n",
      "Inferencing HTTP server version: azmlinfsrv/1.3.3\n",
      "CORS for the specified origins: None\n",
      "Create dedicated endpoint for health: None\n",
      "\n",
      "\n",
      "Server Routes\n",
      "---------------\n",
      "Liveness Probe: GET   127.0.0.1:31311/\n",
      "Score:          POST  127.0.0.1:31311/score\n",
      "\n",
      "2024-10-19 07:56:54,796 W [135] azmlinfsrv - Found extra keys in the config file that are not supported by the server.\n",
      "Extra keys = ['AZUREML_SOURCE_DIRECTORY', 'AZUREML_ENTRY_SCRIPT', 'SERVICE_NAME', 'WORKSPACE_NAME', 'SCORING_TIMEOUT_MS', 'AZUREML_MODEL_DIR', 'HOSTNAME']\n",
      "/azureml-envs/azureml_c0ce3e6b048e85d1440ae5b5f8420e29/lib/python3.8/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_dc_storage_enabled\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
      "  warnings.warn(\n",
      "2024-10-19 07:56:55,281 I [135] azmlinfsrv - AML_FLASK_ONE_COMPATIBILITY is set. Patched Flask to ensure compatibility with Flask 1.\n",
      "Initializing logger\n",
      "2024-10-19 07:56:55,284 I [135] azmlinfsrv - Starting up app insights client\n",
      "2024-10-19 07:56:56,463 I [135] azmlinfsrv.user_script - Found user script at /var/azureml-app/diabetes_service/score_diabetes.py\n",
      "2024-10-19 07:56:56,463 I [135] azmlinfsrv.user_script - run() is not decorated. Server will invoke it with the input in JSON string.\n",
      "2024-10-19 07:56:56,463 I [135] azmlinfsrv.user_script - Invoking user's init function\n",
      "2024-10-19 07:56:57,239 I [135] azmlinfsrv.user_script - Users's init has completed successfully\n",
      "2024-10-19 07:56:57,240 I [135] azmlinfsrv.swagger - Swaggers are prepared for the following versions: [2, 3, 3.1].\n",
      "2024-10-19 07:56:57,240 I [135] azmlinfsrv - Scoring timeout is set to 60000\n",
      "2024-10-19 07:56:57,240 I [135] azmlinfsrv - Worker with pid 135 ready for serving traffic\n",
      "2024-10-19 07:57:07,857 W [135] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2024-10-19 07:57:07,858 I [135] gunicorn.access - 127.0.0.1 - - [19/Oct/2024:07:57:07 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"Go-http-client/1.1\"\n",
      "2024-10-19 07:57:07,860 W [135] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2024-10-19 07:57:07,861 I [135] azmlinfsrv - GET /swagger.json 200 0.522ms 2210\n",
      "2024-10-19 07:57:07,862 I [135] gunicorn.access - 127.0.0.1 - - [19/Oct/2024:07:57:07 +0000] \"GET /swagger.json HTTP/1.0\" 200 2210 \"-\" \"Go-http-client/1.1\"\n",
      "2024-10-19 07:57:11,912 W [135] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2024-10-19 07:57:11,913 I [135] gunicorn.access - 127.0.0.1 - - [19/Oct/2024:07:57:11 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"Go-http-client/1.1\"\n",
      "2024-10-19 07:57:11,916 W [135] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n",
      "2024-10-19 07:57:11,916 I [135] azmlinfsrv - GET /swagger.json 200 0.510ms 2210\n",
      "2024-10-19 07:57:11,918 I [135] gunicorn.access - 127.0.0.1 - - [19/Oct/2024:07:57:11 +0000] \"GET /swagger.json HTTP/1.0\" 200 2210 \"-\" \"Go-http-client/1.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.state)\n",
    "print(service.get_logs())\n",
    "\n",
    "# If you need to make a change and redeploy, you may need to delete unhealthy service using the following code:\n",
    "#service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at your workspace in the [Azure web interface](https://ml.azure.com) and view the **Endpoints** page, which shows the deployed services in your workspace.\n",
    "\n",
    "You can also retrieve the names of web services in your workspace by running the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes-service\n",
      "diabetes-service-app-insights\n"
     ]
    }
   ],
   "source": [
    "for webservice_name in ws.webservices:\n",
    "    print(webservice_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Use the Web Service\n",
    "\n",
    "With the service deployed, now you can consume it from a client application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient: [2, 180, 74, 24, 21, 23.9091702, 1.488172308, 22]\n",
      "diabetic\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22]]\n",
    "print ('Patient: {}'.format(x_new[0]))\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Call the web service, passing the input data (the web service will also accept the data in binary format)\n",
    "predictions = service.run(input_data = input_json)\n",
    "\n",
    "# Get the predicted class - it'll be the first (and only) one.\n",
    "predicted_classes = json.loads(predictions)\n",
    "print(predicted_classes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also send multiple patient observations to the service, and get back a prediction for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient [2, 180, 74, 24, 21, 23.9091702, 1.488172308, 22] diabetic\n",
      "Patient [0, 148, 58, 11, 179, 39.19207553, 0.160829008, 45] not-diabetic\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# This time our input is an array of two feature arrays\n",
    "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22],\n",
    "         [0,148,58,11,179,39.19207553,0.160829008,45]]\n",
    "\n",
    "# Convert the array or arrays to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Call the web service, passing the input data\n",
    "predictions = service.run(input_data = input_json)\n",
    "\n",
    "# Get the predicted classes.\n",
    "predicted_classes = json.loads(predictions)\n",
    "   \n",
    "for i in range(len(x_new)):\n",
    "    print (\"Patient {}\".format(x_new[i]), predicted_classes[i] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above uses the Azure ML SDK to connect to the containerized web service and use it to generate predictions from your diabetes classification model. In production, a model is likely to be consumed by business applications that do not use the Azure ML SDK, but simply make HTTP requests to the web service.\n",
    "\n",
    "Let's determine the URL to which these applications must submit their requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://b039152c-afe7-49f0-8ca0-263f6adbba42.eastus2.azurecontainer.io/score\n"
     ]
    }
   ],
   "source": [
    "endpoint = service.scoring_uri\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you know the endpoint URI, an application can simply make an HTTP request, sending the patient data in JSON (or binary) format, and receive back the predicted class(es)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient [2, 180, 74, 24, 21, 23.9091702, 1.488172308, 22] diabetic\n",
      "Patient [0, 148, 58, 11, 179, 39.19207553, 0.160829008, 45] not-diabetic\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22],\n",
    "         [0,148,58,11,179,39.19207553,0.160829008,45]]\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Set the content type\n",
    "headers = { 'Content-Type':'application/json' }\n",
    "\n",
    "predictions = requests.post(endpoint, input_json, headers = headers)\n",
    "predicted_classes = json.loads(predictions.json())\n",
    "\n",
    "for i in range(len(x_new)):\n",
    "    print (\"Patient {}\".format(x_new[i]), predicted_classes[i] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've deployed your web service as an Azure Container Instance (ACI) service, which requries no authentication. This is fine for development and testing, but for production you should consider deploying to an Azure Kubernetes Service (AKS) cluster and enabling authentication. This would require REST requests to include an **Authorization** header.\n",
    "\n",
    ">**More Information** For more information about publishing a model as a service, see the [documentation](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-deploy-and-where)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
